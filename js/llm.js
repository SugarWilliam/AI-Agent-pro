/**
 * AI Agent Pro v6.0.0 - LLMæœåŠ¡
 * å¤šæ¨¡æ€è¾“å…¥è¾“å‡ºæ”¯æŒ
 */

(function() {
    'use strict';

    const LLMService = {
        currentController: null,
        
        // ==================== å¤šæ¨¡æ€è¾“å…¥å¤„ç† ====================
        async processMultimodalInput(input) {
            const processed = {
                text: '',
                images: [],
                documents: [],
                urls: []
            };

            if (typeof input === 'string') {
                // æ£€æµ‹URL
                const urlRegex = /(https?:\/\/[^\s]+)/g;
                const urls = input.match(urlRegex) || [];
                processed.urls = urls;
                
                // æ£€æµ‹å›¾ç‰‡é“¾æ¥
                const imageRegex = /(https?:\/\/[^\s]+\.(?:jpg|jpeg|png|gif|webp))/gi;
                processed.images = input.match(imageRegex) || [];
                
                processed.text = input.replace(urlRegex, '[é“¾æ¥]').trim();
            } else if (input.files && input.files.length > 0) {
                // å¤„ç†æ–‡ä»¶ä¸Šä¼ 
                for (const file of input.files) {
                    if (file.type.startsWith('image/')) {
                        const base64 = await this.fileToBase64(file);
                        processed.images.push({ name: file.name, data: base64, type: file.type });
                    } else if (file.type === 'application/pdf' || 
                               file.type.includes('word') ||
                               file.type === 'text/plain' ||
                               file.type === 'text/markdown') {
                        const content = await this.readDocument(file);
                        processed.documents.push({ 
                            name: file.name, 
                            content: content,
                            type: file.type 
                        });
                    }
                }
                processed.text = input.text || '';
            }

            return processed;
        },

        // æ–‡ä»¶è½¬Base64
        fileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        },

        // è¯»å–æ–‡æ¡£å†…å®¹
        async readDocument(file) {
            if (file.type === 'text/plain' || file.type === 'text/markdown') {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = () => resolve(reader.result);
                    reader.onerror = reject;
                    reader.readAsText(file);
                });
            }
            
            // PDFå’ŒDOCéœ€è¦åç«¯æ”¯æŒï¼Œè¿™é‡Œè¿”å›å ä½ç¬¦
            if (file.type === 'application/pdf') {
                return `[PDFæ–‡æ¡£: ${file.name}]\n(éœ€è¦åç«¯æœåŠ¡è§£æPDFå†…å®¹)`;
            }
            
            if (file.type.includes('word')) {
                return `[Wordæ–‡æ¡£: ${file.name}]\n(éœ€è¦åç«¯æœåŠ¡è§£æDOCå†…å®¹)`;
            }
            
            return `[æ–‡æ¡£: ${file.name}]`;
        },

        // ==================== æ™ºèƒ½è°ƒç”¨å¼•æ“ ====================
        async invokeIntelligentAgent(messages, options = {}) {
            const {
                modelId = 'auto',
                enableWebSearch = false,
                onStream = null,
                outputFormat = 'markdown',
                taskType = 'general'
            } = options;

            // 1. åˆ†æä»»åŠ¡ç±»å‹
            const taskAnalysis = this.analyzeTaskType(messages, taskType);

            // 2. æ™ºèƒ½é€‰æ‹©æ¨¡å‹
            const actualModelId = modelId === 'auto' 
                ? window.AIAgentApp.autoSelectModel(messages, taskAnalysis.type)
                : modelId;
            
            // 3. è·å–Sub Agentèµ„æº
            const subAgent = window.AIAgentApp.getCurrentSubAgent();
            const resources = window.AIAgentApp.getSubAgentResources(subAgent.id);
            
            // 4. è°ƒç”¨ç›¸å…³Skills
            const skillPrompts = this.buildSkillPrompts(resources.skills, taskAnalysis);
            
            // 5. åº”ç”¨Rules
            const rulesPrompt = this.buildRulesPrompt(resources.rules);
            
            // 6. è°ƒç”¨MCPå·¥å…·
            let mcpResults = [];
            let searchThinking = '';
            if (enableWebSearch && resources.mcp.some(m => m.id === 'mcp_web_search')) {
                const searchResults = await this.performWebSearch(messages[messages.length - 1]?.content);
                if (searchResults.length > 0) {
                    mcpResults.push({ type: 'search', data: searchResults });
                    
                    // å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºæ€è€ƒè¿‡ç¨‹
                    searchThinking = '\n\nğŸ” ç½‘ç»œæœç´¢ç»“æœï¼š\n';
                    searchResults.forEach((result, index) => {
                        searchThinking += `\n${index + 1}. ${result.title}\n   ${result.url}\n   ${result.snippet || ''}\n`;
                    });
                }
            }

            // 7. æŸ¥è¯¢RAGçŸ¥è¯†åº“
            let ragContext = '';
            if (resources.rag && resources.rag.length > 0) {
                ragContext = await this.queryRAG(messages[messages.length - 1]?.content, resources.rag);
            }

            // 8. æ„å»ºå®Œæ•´æç¤ºè¯
            const systemPrompt = this.buildEnhancedSystemPrompt({
                subAgent,
                skillPrompts,
                rulesPrompt,
                mcpResults,
                ragContext,
                outputFormat
            });

            // 9. è°ƒç”¨LLM
            const result = await this.callLLM({
                messages,
                systemPrompt,
                modelId: actualModelId,
                onStream,
                outputFormat,
                taskAnalysis
            });

            // 10. å¦‚æœæœ‰æœç´¢ç»“æœï¼Œæ·»åŠ åˆ°æ€è€ƒè¿‡ç¨‹ä¸­
            if (searchThinking) {
                result.thinking = (result.thinking || '') + searchThinking;
            }

            return result;
        },

        // åˆ†æä»»åŠ¡ç±»å‹
        analyzeTaskType(messages, defaultType) {
            const lastMessage = messages[messages.length - 1];
            const content = lastMessage?.content?.toLowerCase() || '';
            
            const patterns = {
                code: ['ä»£ç ', 'ç¼–ç¨‹', 'bug', 'debug', 'å‡½æ•°', 'class', 'python', 'javascript', 'java'],
                creative: ['åˆ›æ„', 'å†™ä½œ', 'æ•…äº‹', 'è¯—æ­Œ', 'æ–‡æ¡ˆ', 'åˆ›ä½œ'],
                analysis: ['åˆ†æ', 'å†³ç­–', 'å¯¹æ¯”', 'è¯„ä¼°', 'å»ºè®®'],
                planning: ['è®¡åˆ’', 'è§„åˆ’', 'todo', 'ä»»åŠ¡', 'æ—¶é—´è¡¨'],
                research: ['ç ”ç©¶', 'è°ƒç ”', 'èµ„æ–™', 'æ–‡çŒ®'],
                data: ['æ•°æ®', 'è¡¨æ ¼', 'ç»Ÿè®¡', 'å›¾è¡¨'],
                presentation: ['ppt', 'æ¼”ç¤º', 'æ¼”è®²', 'æ±‡æŠ¥'],
                translation: ['ç¿»è¯‘', 'è‹±æ–‡', 'ä¸­æ–‡', 'æ—¥æ–‡'],
                summary: ['æ€»ç»“', 'æ‘˜è¦', 'æ¦‚æ‹¬'],
                design: ['è®¾è®¡', 'ui', 'ux', 'ç•Œé¢']
            };
            
            for (const [type, keywords] of Object.entries(patterns)) {
                if (keywords.some(k => content.includes(k))) {
                    return { type, confidence: 'high' };
                }
            }
            
            return { type: defaultType || 'general', confidence: 'medium' };
        },

        // æ„å»ºSkillæç¤ºè¯
        buildSkillPrompts(skills, taskAnalysis) {
            if (!skills || skills.length === 0) return '';
            
            let prompts = '';
            skills.forEach(skill => {
                if (skill.prompt) {
                    prompts += `## ${skill.name}\n${skill.prompt}\n\n`;
                }
            });
            
            return prompts;
        },

        // æ„å»ºRulesæç¤ºè¯
        buildRulesPrompt(rules) {
            if (!rules || rules.length === 0) return '';
            
            const sortedRules = [...rules].sort((a, b) => (a.priority || 0) - (b.priority || 0));
            return sortedRules.map(r => `- ${r.content}`).join('\n');
        },

        // æŸ¥è¯¢RAGçŸ¥è¯†åº“
        async queryRAG(query, ragList) {
            // ç®€åŒ–ç‰ˆRAGæŸ¥è¯¢ï¼Œå®é™…åº”è¯¥ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æœç´¢
            let context = '';
            
            for (const rag of ragList) {
                if (rag.documents && rag.documents.length > 0) {
                    context += `\nã€${rag.name}ã€‘\n`;
                    // è¿™é‡Œåº”è¯¥è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
                    // æš‚æ—¶è¿”å›æ–‡æ¡£åˆ—è¡¨
                    context += rag.documents.map(d => `- ${d.name}`).join('\n');
                }
            }
            
            return context;
        },

        // æ„å»ºå¢å¼ºç³»ç»Ÿæç¤ºè¯
        buildEnhancedSystemPrompt({ subAgent, skillPrompts, rulesPrompt, mcpResults, ragContext, outputFormat }) {
            let prompt = `ä½ æ˜¯ã€Œ${subAgent.name}ã€ï¼Œ${subAgent.description}\n\n`;
            prompt += subAgent.systemPrompt + '\n\n';
            
            if (rulesPrompt) {
                prompt += `ã€è§„åˆ™ã€‘\n${rulesPrompt}\n\n`;
            }
            
            if (skillPrompts) {
                prompt += `ã€æŠ€èƒ½æŒ‡å¼•ã€‘\n${skillPrompts}\n`;
            }
            
            if (mcpResults.length > 0) {
                prompt += `ã€å·¥å…·ç»“æœã€‘\n`;
                mcpResults.forEach(result => {
                    if (result.type === 'search') {
                        prompt += this.formatSearchResults(result.data) + '\n';
                    }
                });
            }
            
            if (ragContext) {
                prompt += `ã€çŸ¥è¯†åº“å‚è€ƒã€‘\n${ragContext}\n\n`;
            }
            
            // è¾“å‡ºæ ¼å¼è¦æ±‚
            prompt += `ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘\n`;
            prompt += `- é»˜è®¤ä½¿ç”¨Markdownæ ¼å¼\n`;
            prompt += `- ä»£ç å—å¿…é¡»æ ‡æ³¨è¯­è¨€ç±»å‹\n`;
            
            if (outputFormat === 'table') {
                prompt += `- ä½¿ç”¨Markdownè¡¨æ ¼å±•ç¤ºæ•°æ®\n`;
            } else if (outputFormat === 'list') {
                prompt += `- ä½¿ç”¨æœ‰åºæˆ–æ— åºåˆ—è¡¨ç»„ç»‡å†…å®¹\n`;
            }
            
            return prompt;
        },

        // ==================== æ ¸å¿ƒLLMè°ƒç”¨ ====================
        async callLLM({ messages, systemPrompt, modelId, onStream, outputFormat, taskAnalysis }) {
            if (!window.AppState || !window.AppState.models) {
                throw new Error('AppStateæœªåˆå§‹åŒ–');
            }

            const model = window.AppState.models[modelId];
            if (!model) {
                throw new Error('æœªçŸ¥çš„æ¨¡å‹: ' + modelId);
            }

            if (!model.apiKey || model.apiKey.trim() === '') {
                throw new Error(`æ¨¡å‹ ${model.name} æœªé…ç½®API Keyï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®`);
            }

            // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            const validMessages = messages.filter(msg => msg.role === 'user' || msg.role === 'assistant');
            const formattedMessages = [
                { role: 'system', content: systemPrompt },
                ...validMessages.map(msg => ({
                    role: msg.role,
                    content: msg.content
                }))
            ];

            // æ ¹æ®providerè°ƒç”¨ä¸åŒAPI
            switch(model.provider) {
                case 'deepseek':
                    return await this.callDeepSeekStream(formattedMessages, model, onStream);
                case 'glm':
                    return await this.callGLMStream(formattedMessages, model, onStream);
                case 'kimi':
                    return await this.callKimiStream(formattedMessages, model, onStream);
                case 'qwen':
                    return await this.callQwen(formattedMessages, model, onStream);
                case 'openai':
                    return await this.callOpenAIStream(formattedMessages, model, onStream);
                case 'anthropic':
                    return await this.callAnthropic(formattedMessages, model);
                default:
                    return await this.callGenericOpenAI(formattedMessages, model, onStream);
            }
        },

        // ==================== APIè°ƒç”¨å®ç° ====================
        async callDeepSeekStream(messages, model, onStream) {
            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: model.id.includes('reasoner') ? 'deepseek-reasoner' : 'deepseek-chat',
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7,
                    max_tokens: model.maxTokens || 8192
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`DeepSeek APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';
            let thinking = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta;
                            
                            if (delta) {
                                if (delta.reasoning_content) {
                                    thinking += delta.reasoning_content;
                                }
                                if (delta.content) {
                                    content += delta.content;
                                    if (onStream) onStream(content);
                                }
                            }
                        } catch (e) {
                            console.error('è§£ææµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking };
        },

        async callGLMStream(messages, model, onStream) {
            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: model.id,
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7,
                    max_tokens: model.maxTokens || 4096
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`GLM APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta?.content;
                            if (delta) {
                                content += delta;
                                if (onStream) onStream(content);
                            }
                        } catch (e) {
                            console.error('è§£æ GLM æµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking: '' };
        },

        async callKimiStream(messages, model, onStream) {
            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: 'moonshot-v1-8k',
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`Kimi APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta?.content;
                            if (delta) {
                                content += delta;
                                if (onStream) onStream(content);
                            }
                        } catch (e) {
                            console.error('è§£æ Kimi æµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking: '' };
        },

        async callQwen(messages, model, onStream) {
            // ä½¿ç”¨å…¼å®¹æ¨¡å¼APIï¼ˆOpenAIæ ¼å¼ï¼‰
            // ç¡®ä¿URLæ­£ç¡®æ‹¼æ¥
            const baseUrl = model.url.replace(/\/$/, '');
            const apiUrl = baseUrl + '/chat/completions';
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: 'qwen-max',
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7,
                    max_tokens: model.maxTokens || 4096
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`Qwen APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';
            let thinking = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta;
                            
                            if (delta) {
                                if (delta.reasoning_content) {
                                    thinking += delta.reasoning_content;
                                }
                                if (delta.content) {
                                    content += delta.content;
                                    if (onStream) onStream(content);
                                }
                            }
                        } catch (e) {
                            console.error('è§£æ Qwen æµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking };
        },

        async callOpenAIStream(messages, model, onStream) {
            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: model.id,
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7,
                    max_tokens: model.maxTokens || 4096
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`OpenAI APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta?.content;
                            if (delta) {
                                content += delta;
                                if (onStream) onStream(content);
                            }
                        } catch (e) {
                            console.error('è§£æ OpenAI æµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking: '' };
        },

        async callAnthropic(messages, model) {
            const systemMsg = messages.find(m => m.role === 'system');
            const otherMsgs = messages.filter(m => m.role !== 'system');

            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': model.apiKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify({
                    model: 'claude-3-sonnet-20240229',
                    max_tokens: model.maxTokens || 4096,
                    temperature: model.temperature || 0.7,
                    system: systemMsg?.content,
                    messages: otherMsgs
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`Anthropic APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const data = await response.json();
            return { content: data.content?.[0]?.text || '', thinking: '' };
        },

        async callGenericOpenAI(messages, model, onStream) {
            const response = await fetch(model.url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${model.apiKey}`
                },
                body: JSON.stringify({
                    model: model.id,
                    messages: messages,
                    stream: true,
                    temperature: model.temperature || 0.7,
                    max_tokens: model.maxTokens || 4096
                })
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`APIé”™è¯¯: ${response.status} - ${error}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let content = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;
                        
                        try {
                            const json = JSON.parse(data);
                            const delta = json.choices?.[0]?.delta?.content;
                            if (delta) {
                                content += delta;
                                if (onStream) onStream(content);
                            }
                        } catch (e) {
                            console.error('è§£æè‡ªå®šä¹‰æ¨¡å‹æµæ•°æ®å¤±è´¥:', e);
                        }
                    }
                }
            }

            return { content, thinking: '' };
        },

        // ==================== ç½‘ç»œæœç´¢ ====================
        async performWebSearch(query) {
            try {
                // ä½¿ç”¨ Jina AI è¿›è¡Œç½‘ç»œæœç´¢
                const searchUrl = `https://r.jina.ai/http://www.google.com/search?q=${encodeURIComponent(query)}`;
                const response = await fetch(searchUrl);
                
                if (!response.ok) {
                    console.error('ç½‘ç»œæœç´¢å¤±è´¥:', response.status);
                    return [];
                }
                
                const html = await response.text();
                
                // è§£ææœç´¢ç»“æœï¼ˆç®€åŒ–ç‰ˆï¼‰
                const results = this.parseGoogleSearchResults(html);
                
                return results.slice(0, 5); // é™åˆ¶è¿”å›å‰5ä¸ªç»“æœ
            } catch (error) {
                console.error('ç½‘ç»œæœç´¢å¼‚å¸¸:', error);
                return [];
            }
        },

        parseGoogleSearchResults(html) {
            const results = [];
            
            // ç®€å•çš„HTMLè§£æï¼Œæå–æœç´¢ç»“æœ
            const titleRegex = /<h3[^>]*>(.*?)<\/h3>/gi;
            const linkRegex = /<a[^>]*href="([^"]*)"[^>]*>(.*?)<\/a>/gi;
            const snippetRegex = /<div[^>]*class="[^"]*st[^"]*"[^>]*>(.*?)<\/div>/gi;
            
            let titleMatch;
            const titles = [];
            while ((titleMatch = titleRegex.exec(html)) !== null) {
                titles.push(this.stripHtmlTags(titleMatch[1]));
            }
            
            let linkMatch;
            const links = [];
            while ((linkMatch = linkRegex.exec(html)) !== null) {
                links.push({
                    url: linkMatch[1],
                    title: this.stripHtmlTags(linkMatch[2])
                });
            }
            
            // ç»„åˆç»“æœ
            for (let i = 0; i < Math.min(titles.length, links.length); i++) {
                results.push({
                    title: titles[i] || links[i].title,
                    url: links[i].url,
                    snippet: titles[i] || ''
                });
            }
            
            return results;
        },

        stripHtmlTags(html) {
            return html.replace(/<[^>]*>/g, '').trim();
        },

        async fetchWebPage(url) {
            try {
                // ä½¿ç”¨ Jina AI æŠ“å–ç½‘é¡µå†…å®¹
                const fetchUrl = `https://r.jina.ai/http://${url.replace(/^https?:\/\//, '')}`;
                const response = await fetch(fetchUrl);
                
                if (!response.ok) {
                    throw new Error(`æŠ“å–ç½‘é¡µå¤±è´¥: ${response.status}`);
                }
                
                const content = await response.text();
                
                return {
                    url: url,
                    title: this.extractTitle(content),
                    content: this.stripHtmlTags(content).substring(0, 5000) // é™åˆ¶å†…å®¹é•¿åº¦
                };
            } catch (error) {
                console.error('æŠ“å–ç½‘é¡µå¼‚å¸¸:', error);
                throw error;
            }
        },

        extractTitle(html) {
            const titleMatch = html.match(/<title>(.*?)<\/title>/i);
            return titleMatch ? titleMatch[1].trim() : 'æœªçŸ¥æ ‡é¢˜';
        },

        formatSearchResults(results) {
            if (!results || results.length === 0) return '';
            
            let formatted = 'ã€æœç´¢ç»“æœã€‘\n';
            results.forEach((result, i) => {
                formatted += `${i + 1}. [${result.title}](${result.url})\n${result.snippet}\n\n`;
            });
            return formatted;
        },

        // ==================== å¤šæ¨¡æ€è¾“å‡ºå¤„ç† ====================
        async processMultimodalOutput(content, format) {
            switch(format) {
                case 'markdown':
                    return { type: 'markdown', content };
                case 'html':
                    return { type: 'html', content: this.markdownToHTML(content) };
                case 'table':
                    return { type: 'table', content: this.extractTables(content) };
                case 'pdf':
                    return { type: 'pdf', content: '(PDFç”Ÿæˆéœ€è¦åç«¯æ”¯æŒ)' };
                case 'ppt':
                    return { type: 'ppt', content: this.extractSlides(content) };
                case 'h5':
                    return { type: 'h5', content: this.markdownToH5(content) };
                case 'spreadsheet':
                    return { type: 'spreadsheet', content: this.extractTables(content) };
                default:
                    return { type: 'markdown', content };
            }
        },

        markdownToHTML(markdown) {
            // ç®€åŒ–çš„Markdownè½¬HTML
            let html = markdown
                .replace(/^### (.*$)/gim, '<h3>$1</h3>')
                .replace(/^## (.*$)/gim, '<h2>$1</h2>')
                .replace(/^# (.*$)/gim, '<h1>$1</h1>')
                .replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>')
                .replace(/\*([^*]+)\*/g, '<em>$1</em>')
                .replace(/`([^`]+)`/g, '<code>$1</code>')
                .replace(/\n/g, '<br>');
            return html;
        },

        markdownToH5(markdown) {
            // ç”ŸæˆH5é¡µé¢ç»“æ„
            return {
                title: 'ç”Ÿæˆçš„H5é¡µé¢',
                content: this.markdownToHTML(markdown),
                style: 'mobile-responsive'
            };
        },

        extractTables(content) {
            // æå–Markdownè¡¨æ ¼
            const tableRegex = /\|(.+)\|\n\|[-:| ]+\|\n((?:\|.+\|\n?)+)/g;
            const tables = [];
            let match;
            while ((match = tableRegex.exec(content)) !== null) {
                tables.push(match[0]);
            }
            return tables;
        },

        extractSlides(content) {
            // æå–PPTå¹»ç¯ç‰‡ç»“æ„
            const slides = content.split(/#{2,3} /).filter(s => s.trim()).map((slide, i) => ({
                id: i + 1,
                title: slide.split('\n')[0],
                content: slide.split('\n').slice(1).join('\n')
            }));
            return slides;
        },

        // ==================== ç®€åŒ–ç‰ˆsendMessageï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰====================
        async sendMessage(messages, modelId, enableWebSearch = false, onStream = null) {
            // ä½¿ç”¨æ™ºèƒ½è°ƒç”¨å¼•æ“å‘é€æ¶ˆæ¯
            return await this.invokeIntelligentAgent(messages, {
                modelId: modelId || 'auto',
                enableWebSearch,
                onStream,
                outputFormat: 'markdown',
                taskType: 'general'
            });
        }
    };

    // æš´éœ²åˆ°å…¨å±€
    window.LLMService = LLMService;
})();
